{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "colab-header"
   },
   "source": [
    "# Vietnamese ASR Evaluation - Custom Analysis Example\n",
    "\n",
    "This notebook demonstrates how to use individual modules for custom analysis and evaluation.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/quangnt03/vietnamese-asr-benchmark/blob/main/custom_analysis_example.ipynb)\n",
    "\n",
    "**Note**: This notebook is compatible with Google Colab. The setup cells below will automatically install dependencies and clone the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## [CONFIG] Google Colab Setup\n",
    "\n",
    "Run these cells if you're using Google Colab. They will:\n",
    "1. Detect if running on Colab\n",
    "2. Clone the repository\n",
    "3. Install all required dependencies\n",
    "4. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "check-colab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Running locally\n"
     ]
    }
   ],
   "source": [
    "# Check if running on Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"[OK] Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"[OK] Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Colab setup (running locally)\n"
     ]
    }
   ],
   "source": [
    "# Clone repository and install dependencies (Colab only)\n",
    "if IN_COLAB:\n",
    "    print(\"Setting up environment for Google Colab...\\n\")\n",
    "    \n",
    "    # Clone the repository\n",
    "    print(\" Cloning repository...\")\n",
    "    !git clone https://github.com/quangnt03/vietnamese-asr-benchmark.git\n",
    "    \n",
    "    # Change to repository directory\n",
    "    import os\n",
    "    os.chdir('vietnamese-asr-benchmark')\n",
    "    print(f\"[OK] Changed directory to: {os.getcwd()}\")\n",
    "    \n",
    "    # Install dependencies\n",
    "    print(\"\\n[PACKAGE] Installing dependencies...\")\n",
    "    !pip install -q -r requirements.txt\n",
    "    \n",
    "    print(\"\\n[OK] Setup complete! You can now run the notebook.\")\n",
    "else:\n",
    "    print(\"Skipping Colab setup (running locally)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify-setup"
   },
   "outputs": [],
   "source": [
    "# Verify installation\n",
    "if IN_COLAB:\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "    \n",
    "    print(\"Verifying installation...\")\n",
    "    print(f\"Python version: {sys.version.split()[0]}\")\n",
    "    print(f\"Working directory: {Path.cwd()}\")\n",
    "    \n",
    "    # Check if key files exist in new structure\n",
    "    key_files = ['src/metrics.py', 'src/dataset_loader.py', \n",
    "                 'src/model_evaluator.py', 'src/visualization.py']\n",
    "    for file in key_files:\n",
    "        if Path(file).exists():\n",
    "            print(f\"  [OK] {file}\")\n",
    "        else:\n",
    "            print(f\"  [FAILED] {file} - NOT FOUND\")\n",
    "    \n",
    "    print(\"\\n[OK] Verification complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-imports"
   },
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path for local execution\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Import custom modules\n",
    "from src.metrics import ASRMetrics, format_metrics_report\n",
    "from src.dataset_loader import DatasetManager\n",
    "from src.model_evaluator import ModelEvaluator, ModelFactory\n",
    "from src.visualization import ASRVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "metrics-header"
   },
   "source": [
    "## 2. Using the Metrics Module\n",
    "\n",
    "Calculate ASR metrics for individual transcriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "metrics-single"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "                      Example Metrics                       \n",
      "============================================================\n",
      "\n",
      "Word Error Rate (WER):           0.1429 (14.29%)\n",
      "Character Error Rate (CER):      0.1333 (13.33%)\n",
      "Match Error Rate (MER):          0.1429 (14.29%)\n",
      "Word Information Lost (WIL):     0.1429 (14.29%)\n",
      "Word Information Preserved (WIP): 0.8571 (85.71%)\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize metrics calculator\n",
    "calculator = ASRMetrics()\n",
    "\n",
    "# Example Vietnamese text\n",
    "reference = \"xin chào tôi là người việt nam\"\n",
    "hypothesis = \"xin chào tôi là người việt\"\n",
    "\n",
    "# Calculate all metrics\n",
    "metrics = calculator.calculate_all_metrics(reference, hypothesis)\n",
    "\n",
    "print(format_metrics_report(metrics, \"Example Metrics\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "metrics-batch"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "                       Batch Metrics                        \n",
      "============================================================\n",
      "\n",
      "Word Error Rate (WER):           0.1143 (11.43%)\n",
      "Character Error Rate (CER):      0.1079 (10.79%)\n",
      "Match Error Rate (MER):          0.1032 (10.32%)\n",
      "Word Information Lost (WIL):     0.1032 (10.32%)\n",
      "Word Information Preserved (WIP): 0.8968 (89.68%)\n",
      "Sentence Error Rate (SER):       0.6667 (66.67%)\n",
      "\n",
      "                      Error Breakdown                       \n",
      "------------------------------------------------------------\n",
      "Total Words:                     16\n",
      "Hits:                            15\n",
      "Substitutions:                   0\n",
      "Deletions:                       1\n",
      "Insertions:                      1\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Batch evaluation\n",
    "references = [\n",
    "    \"xin chào tôi là người việt nam\",\n",
    "    \"hôm nay thời tiết đẹp\",\n",
    "    \"tôi yêu tiếng việt\"\n",
    "]\n",
    "\n",
    "hypotheses = [\n",
    "    \"xin chào tôi là người việt\",\n",
    "    \"hôm nay thời tiết đẹp quá\",\n",
    "    \"tôi yêu tiếng việt\"\n",
    "]\n",
    "\n",
    "batch_metrics = calculator.calculate_batch_metrics(references, hypotheses)\n",
    "\n",
    "print(format_metrics_report(batch_metrics, \"Batch Metrics\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "datasets-header"
   },
   "source": [
    "## 3. Loading and Analyzing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "datasets-load"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Loading local datasets\n",
      "======================================================================\n",
      "\n",
      "Loading ViMD dataset...\n",
      "Warning: ViMD metadata file not found at data/vimd/transcripts/metadata.csv\n",
      "Creating synthetic example for demonstration...\n",
      "Creating 100 synthetic samples for vimd...\n",
      "Loading BUD500 dataset...\n",
      "Warning: BUD500 data directory not found at data/bud500\n",
      "Creating 50 synthetic samples for bud500...\n",
      "Loading LSVSC dataset...\n",
      "Warning: LSVSC data directory not found at data/lsvsc\n",
      "Creating 100 synthetic samples for lsvsc...\n",
      "Loading VLSP 2020 dataset...\n",
      "Warning: VLSP2020 data directory not found at data/vlsp2020\n",
      "Creating 80 synthetic samples for vlsp2020...\n",
      "Loading VietMed dataset...\n",
      "Warning: VietMed data directory not found at data/vietmed\n",
      "Creating 60 synthetic samples for vietmed...\n",
      "\n",
      "Dataset Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Num Samples</th>\n",
       "      <th>Total Duration (hours)</th>\n",
       "      <th>Avg Duration (seconds)</th>\n",
       "      <th>Num Speakers</th>\n",
       "      <th>Num Dialects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ViMD</td>\n",
       "      <td>100</td>\n",
       "      <td>0.111167</td>\n",
       "      <td>4.002000</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUD500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.053376</td>\n",
       "      <td>3.843106</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSVSC</td>\n",
       "      <td>100</td>\n",
       "      <td>0.109559</td>\n",
       "      <td>3.944106</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VLSP2020</td>\n",
       "      <td>80</td>\n",
       "      <td>0.088696</td>\n",
       "      <td>3.991313</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VietMed</td>\n",
       "      <td>60</td>\n",
       "      <td>0.067053</td>\n",
       "      <td>4.023204</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dataset  Num Samples  Total Duration (hours)  Avg Duration (seconds)  \\\n",
       "0      ViMD          100                0.111167                4.002000   \n",
       "1    BUD500           50                0.053376                3.843106   \n",
       "2     LSVSC          100                0.109559                3.944106   \n",
       "3  VLSP2020           80                0.088696                3.991313   \n",
       "4   VietMed           60                0.067053                4.023204   \n",
       "\n",
       "   Num Speakers  Num Dialects  \n",
       "0            10             3  \n",
       "1            10             3  \n",
       "2            10             3  \n",
       "3            10             3  \n",
       "4            10             3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize dataset manager\n",
    "manager = DatasetManager(base_data_dir=\"./data\")\n",
    "\n",
    "# Load datasets (will use synthetic data if real data not available)\n",
    "datasets = manager.load_all_datasets()\n",
    "\n",
    "# Get statistics\n",
    "stats_df = manager.get_dataset_statistics()\n",
    "print(\"\\nDataset Statistics:\")\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "datasets-split"
   },
   "outputs": [],
   "source": [
    "# Prepare train/test splits\n",
    "splits = manager.prepare_train_test_splits(\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15\n",
    ")\n",
    "\n",
    "# Examine a specific dataset\n",
    "print(\"\\nViMD Test Set:\")\n",
    "test_samples = splits['ViMD']['test']\n",
    "print(f\"Number of samples: {len(test_samples)}\")\n",
    "print(f\"First sample: {test_samples[0].transcription if test_samples else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "models-header"
   },
   "source": [
    "## 4. Working with ASR Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "models-list"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "  phowhisper-tiny: PhoWhisper-tiny\n",
      "  phowhisper-base: PhoWhisper-base\n",
      "  phowhisper-small: PhoWhisper-small\n",
      "  phowhisper-medium: PhoWhisper-medium\n",
      "  phowhisper-large: PhoWhisper-large\n",
      "  whisper-small: Whisper-small\n",
      "  whisper-medium: Whisper-medium\n",
      "  whisper-large: Whisper-large-v3\n",
      "  wav2vec2-xlsr-vietnamese: Wav2Vec2-XLSR-Vietnamese\n",
      "  wav2vec2-base-vietnamese: Wav2Vec2-Base-Vietnamese\n",
      "  wav2vn: Wav2Vn\n"
     ]
    }
   ],
   "source": [
    "# List available models\n",
    "print(\"Available models:\")\n",
    "for model_key in ModelFactory.get_available_models():\n",
    "    config = ModelFactory.MODEL_CONFIGS[model_key]\n",
    "    print(f\"  {model_key}: {config.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "models-load"
   },
   "outputs": [],
   "source": [
    "# Load specific models\n",
    "evaluator = ModelEvaluator(\n",
    "    models_to_evaluate=['phowhisper-small', 'whisper-small']\n",
    ")\n",
    "\n",
    "evaluator.load_models()\n",
    "models = evaluator.get_loaded_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "models-transcribe"
   },
   "outputs": [],
   "source": [
    "# Transcribe a sample audio (example with mock data)\n",
    "if models:\n",
    "    model_name = list(models.keys())[0]\n",
    "    model = models[model_name]\n",
    "    \n",
    "    # Mock transcription\n",
    "    transcription = model.transcribe(\"sample_audio.wav\")\n",
    "    print(f\"{model_name} transcription: {transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation-header"
   },
   "source": [
    "## 5. Custom Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluation-custom"
   },
   "outputs": [],
   "source": [
    "# Example: Evaluate a specific model on a specific dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def evaluate_model_on_dataset(model, samples, max_samples=10):\n",
    "    \"\"\"\n",
    "    Custom evaluation function.\n",
    "    \"\"\"\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    \n",
    "    for sample in tqdm(samples[:max_samples], desc=\"Transcribing\"):\n",
    "        hypothesis = model.transcribe(sample.audio_path)\n",
    "        references.append(sample.transcription)\n",
    "        hypotheses.append(hypothesis)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    calculator = ASRMetrics()\n",
    "    metrics = calculator.calculate_batch_metrics(references, hypotheses)\n",
    "    \n",
    "    return metrics, references, hypotheses\n",
    "\n",
    "# Run evaluation\n",
    "if models and splits:\n",
    "    model_name = list(models.keys())[0]\n",
    "    dataset_name = list(splits.keys())[0]\n",
    "    \n",
    "    print(f\"\\nEvaluating {model_name} on {dataset_name}...\")\n",
    "    metrics, refs, hyps = evaluate_model_on_dataset(\n",
    "        models[model_name],\n",
    "        splits[dataset_name]['test'],\n",
    "        max_samples=5\n",
    "    )\n",
    "    \n",
    "    print(format_metrics_report(metrics, f\"{model_name} on {dataset_name}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis-header"
   },
   "source": [
    "## 6. Analyzing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analysis-load"
   },
   "outputs": [],
   "source": [
    "# Load results from CSV (if available)\n",
    "results_path = \"./results/evaluation_results_*.csv\"\n",
    "import glob\n",
    "\n",
    "csv_files = glob.glob(str(Path(\"./results\") / \"evaluation_results_*.csv\"))\n",
    "\n",
    "if csv_files:\n",
    "    results_df = pd.read_csv(csv_files[0])\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    display(results_df[['Model', 'Dataset', 'wer', 'cer', 'mer', 'ser']])\n",
    "else:\n",
    "    print(\"No results file found. Run the main evaluation first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analysis-best"
   },
   "outputs": [],
   "source": [
    "# Custom analysis: Best model per dataset\n",
    "if csv_files and 'results_df' in locals():\n",
    "    best_models = results_df.loc[results_df.groupby('Dataset')['wer'].idxmin()]\n",
    "    print(\"\\nBest Model per Dataset (by WER):\")\n",
    "    display(best_models[['Dataset', 'Model', 'wer', 'cer']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viz-header"
   },
   "source": [
    "## 7. Creating Custom Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-prepare"
   },
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = ASRVisualizer(output_dir=\"./custom_plots\")\n",
    "\n",
    "# Create synthetic data for demonstration\n",
    "if not csv_files:\n",
    "    # Generate sample data\n",
    "    models = ['PhoWhisper-small', 'Whisper-small']\n",
    "    datasets = ['ViMD', 'VLSP2020']\n",
    "    \n",
    "    results_data = []\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            results_data.append({\n",
    "                'Model': model,\n",
    "                'Dataset': dataset,\n",
    "                'wer': np.random.uniform(0.10, 0.20),\n",
    "                'cer': np.random.uniform(0.05, 0.12),\n",
    "                'mer': np.random.uniform(0.08, 0.15),\n",
    "                'wil': np.random.uniform(0.12, 0.25),\n",
    "                'ser': np.random.uniform(0.20, 0.35),\n",
    "                'rtf_mean': np.random.uniform(0.2, 0.4),\n",
    "                'total_insertions': np.random.randint(5, 20),\n",
    "                'total_deletions': np.random.randint(5, 20),\n",
    "                'total_substitutions': np.random.randint(10, 30)\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(results_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-create"
   },
   "outputs": [],
   "source": [
    "# Create individual plots\n",
    "visualizer.plot_metric_comparison(results_df, metric='wer')\n",
    "visualizer.plot_all_metrics_heatmap(results_df)\n",
    "visualizer.plot_model_performance_radar(results_df)\n",
    "\n",
    "print(\"\\nPlots saved to: ./custom_plots/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export-header"
   },
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export-results"
   },
   "outputs": [],
   "source": [
    "# Export to different formats\n",
    "if 'results_df' in locals():\n",
    "    # CSV\n",
    "    results_df.to_csv('./custom_results.csv', index=False)\n",
    "    \n",
    "    # Excel (requires openpyxl)\n",
    "    # results_df.to_excel('./custom_results.xlsx', index=False)\n",
    "    \n",
    "    # JSON\n",
    "    results_df.to_json('./custom_results.json', orient='records', indent=2)\n",
    "    \n",
    "    print(\"Results exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. [OK] Using the metrics module for ASR evaluation\n",
    "2. [OK] Loading and analyzing Vietnamese datasets\n",
    "3. [OK] Working with multiple ASR models\n",
    "4. [OK] Custom evaluation workflows\n",
    "5. [OK] Analyzing and visualizing results\n",
    "6. [OK] Exporting results in various formats\n",
    "\n",
    "For automated evaluation, use `main_evaluation.py` instead!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lactech-stt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
